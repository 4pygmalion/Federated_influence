{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code provide the estmation results (calibration) between the change of estimated loss without train data z and acutal loss without loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import linear_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "from influence_utils import grad_z\n",
    "from influence_utils import get_hessian_vector_product\n",
    "from influence_utils import get_inv_hessian_vector_product\n",
    "from influence_utils import multiply_for_influe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2class_mnist(num_a, num_b):\n",
    "    from tensorflow.keras.datasets import mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data(path='mnist.npz')\n",
    "    x_train, x_test = x_train.reshape([-1, 784]) / 255.0, x_test.reshape([-1, 784]) / 255.0\n",
    "    x_train_2class, y_train_2class = from10to2classes(x_train, y_train, num_a, num_b)\n",
    "    x_test_2class, y_test_2class = from10to2classes(x_test, y_test, num_a, num_b)\n",
    "\n",
    "    return (x_train_2class, y_train_2class), (x_test_2class, y_test_2class)\n",
    "\n",
    "def from10to2classes(x, y, num_a, num_b):\n",
    "    is_num_a, is_num_b = y == num_a, y == num_b\n",
    "    x_2class = np.concatenate([x[is_num_a], x[is_num_b]])\n",
    "    y_2class = np.concatenate([np.ones(is_num_a.sum()), np.zeros(is_num_b.sum())]).reshape([-1, 1])\n",
    "\n",
    "    return x_2class, y_2class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.007688167909587146, tol=1e-08)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_A, NUM_B = 1, 7\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_2class_mnist(NUM_A, NUM_B)\n",
    "train_sample_num = len(x_train)\n",
    "\n",
    "# prepare sklearn model to train w\n",
    "C = 1.0 / (train_sample_num * WEIGHT_DECAY)\n",
    "sklearn_model = linear_model.LogisticRegression(C=C, solver='lbfgs', tol=1e-8, fit_intercept=True)\n",
    "sklearn_model.fit(x_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ref = sklearn_model.coef_.ravel()\n",
    "b_ref = sklearn_model.intercept_.ravel()\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid', use_bias=True))\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.set_weights([w_ref.reshape(784, 1), b_ref])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grad_z test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784,), (1,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_INDEX = 5\n",
    "\n",
    "x_test_tf = tf.convert_to_tensor(x_test[TEST_INDEX: TEST_INDEX+1])\n",
    "y_test_tf = tf.convert_to_tensor(y_test[TEST_INDEX: TEST_INDEX+1])\n",
    "\n",
    "test_grad_my = grad_z(x_test_tf, y_test_tf, f=model)\n",
    "\n",
    "# as vector\n",
    "test_grad_my_coef = test_grad_my[0].numpy().ravel() \n",
    "test_grad_my_bias = test_grad_my[1].numpy().ravel() \n",
    "test_grad_my_coef.shape, test_grad_my_bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### grad_z_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784,), (1,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "x_train_tf = tf.convert_to_tensor(x_train[0:2])\n",
    "y_train_tf = tf.convert_to_tensor(y_train[0:2])\n",
    "\n",
    "train_grad_my = grad_z(x_train_tf, y_train_tf, model, for_train=True)\n",
    "\n",
    "# as vector\n",
    "train_grad_my_coef = train_grad_my[0].numpy().ravel() \n",
    "train_grad_my_bias = train_grad_my[1].numpy().ravel() \n",
    "\n",
    "train_grad_my_coef.shape, train_grad_my_bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### hvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tf = tf.convert_to_tensor(x_train)\n",
    "y_train_tf = tf.convert_to_tensor(y_train)\n",
    "x_test_tf = tf.convert_to_tensor(x_test[TEST_INDEX: TEST_INDEX+1])\n",
    "y_test_tf = tf.convert_to_tensor(y_test[TEST_INDEX: TEST_INDEX+1])\n",
    "\n",
    "test_grad_my = grad_z(x_test_tf, y_test_tf, f=model)\n",
    "\n",
    "hvp_my = get_hessian_vector_product(x_train_tf, y_train_tf, model, test_grad_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train, Y train shape: (13007, 784) (13007, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_tf = tf.convert_to_tensor(x_train)\n",
    "y_train_tf = tf.convert_to_tensor(y_train)\n",
    "\n",
    "print(\"X train, Y train shape:\", x_train_tf.shape, y_train_tf.shape)\n",
    "\n",
    "\n",
    "s_test_my = get_inv_hessian_vector_product(x_train_tf, y_train_tf, test_grad_my, model,\n",
    "                                            scale=10,\n",
    "                                            n_recursion=1000,\n",
    "                                            verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/13007] Estimated loss diff: -7.702806358086522e-07\n",
      "[1001/13007] Estimated loss diff: -9.373290015303932e-07\n",
      "[2001/13007] Estimated loss diff: -2.4879551259568087e-06\n",
      "[3001/13007] Estimated loss diff: -1.5328967587354596e-07\n",
      "[4001/13007] Estimated loss diff: 3.3219717206703927e-06\n",
      "[5001/13007] Estimated loss diff: -1.086079219363411e-06\n",
      "[6001/13007] Estimated loss diff: -1.7927988778174762e-06\n",
      "[7001/13007] Estimated loss diff: -5.516122892785949e-07\n",
      "[8001/13007] Estimated loss diff: -7.902691955687115e-07\n",
      "[9001/13007] Estimated loss diff: -7.719216582089596e-07\n",
      "[10001/13007] Estimated loss diff: -9.1404048872746e-07\n",
      "[11001/13007] Estimated loss diff: -8.671315044778713e-07\n",
      "[12001/13007] Estimated loss diff: -3.552140707487059e-06\n",
      "[13001/13007] Estimated loss diff: -7.409470043527974e-07\n"
     ]
    }
   ],
   "source": [
    "train_sample_num = len(x_train_tf)\n",
    "loss_diff_approx = np.zeros(train_sample_num)\n",
    "\n",
    "for i in range(train_sample_num):\n",
    "    \n",
    "    # Get train grad\n",
    "    train_grad = grad_z(x_train_tf[i: i+1], y_train[i: i+1], model, for_train=True)\n",
    "    loss_diff_approx[i] = multiply_for_influe(train_grad, s_test_my) / train_sample_num\n",
    "\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print('[{}/{}] Estimated loss diff: {}'.format(i+1, train_sample_num, loss_diff_approx[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### influence function calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test original loss\n",
    "\n",
    "TEST_INDEX = 5\n",
    "\n",
    "x_test_tf = tf.convert_to_tensor(x_test[TEST_INDEX: TEST_INDEX+1])\n",
    "y_test_tf = tf.convert_to_tensor(y_test[TEST_INDEX: TEST_INDEX+1])\n",
    "\n",
    "w_ref = sklearn_model.coef_.T.ravel()\n",
    "b_ref = sklearn_model.intercept_.ravel()\n",
    "model.set_weights([w_ref.reshape(784, 1), b_ref])\n",
    "\n",
    "\n",
    "y_hat = model.predict(x_test_tf)\n",
    "test_loss_ori = tf.keras.losses.binary_crossentropy(y_test_tf, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01704626]\n",
      "True loss diff      :0.0001205839216709137\n",
      "Estimated loss diff :4.5293565397603697e-05\n",
      "[2/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.0170468]\n",
      "True loss diff      :0.00012112967669963837\n",
      "Estimated loss diff :4.8181726730070556e-05\n",
      "[3/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01703346]\n",
      "True loss diff      :0.00010779127478599548\n",
      "Estimated loss diff :4.8534395182500235e-05\n",
      "[4/50]\n",
      "LBFGS training took [23] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01704498]\n",
      "True loss diff      :0.00011931173503398895\n",
      "Estimated loss diff :5.34562449943825e-05\n",
      "[5/50]\n",
      "LBFGS training took [23] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01704262]\n",
      "True loss diff      :0.00011694617569446564\n",
      "Estimated loss diff :5.376061079922688e-05\n",
      "[6/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01704826]\n",
      "True loss diff      :0.00012258440256118774\n",
      "Estimated loss diff :5.706001509605642e-05\n",
      "[7/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01705844]\n",
      "True loss diff      :0.00013277120888233185\n",
      "Estimated loss diff :5.804051203246376e-05\n",
      "[8/50]\n",
      "LBFGS training took [21] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01703813]\n",
      "True loss diff      :0.00011246092617511749\n",
      "Estimated loss diff :5.8729203058886586e-05\n",
      "[9/50]\n",
      "LBFGS training took [23] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01704965]\n",
      "True loss diff      :0.00012397952377796173\n",
      "Estimated loss diff :6.062697805077619e-05\n",
      "[10/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01705014]\n",
      "True loss diff      :0.00012446381151676178\n",
      "Estimated loss diff :6.443351337347792e-05\n",
      "[11/50]\n",
      "LBFGS training took [23] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01705281]\n",
      "True loss diff      :0.00012713298201560974\n",
      "Estimated loss diff :6.452915677217221e-05\n",
      "[12/50]\n",
      "LBFGS training took [21] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01707439]\n",
      "True loss diff      :0.00014871731400489807\n",
      "Estimated loss diff :6.463569171163629e-05\n",
      "[13/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01705329]\n",
      "True loss diff      :0.0001276172697544098\n",
      "Estimated loss diff :6.735057792649735e-05\n",
      "[14/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01706275]\n",
      "True loss diff      :0.0001370757818222046\n",
      "Estimated loss diff :6.78618926363885e-05\n",
      "[15/50]\n",
      "LBFGS training took [23] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01711471]\n",
      "True loss diff      :0.0001890379935503006\n",
      "Estimated loss diff :7.005174884658118e-05\n",
      "[16/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01706323]\n",
      "True loss diff      :0.00013756006956100464\n",
      "Estimated loss diff :7.420006290678471e-05\n",
      "[17/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01706263]\n",
      "True loss diff      :0.00013695470988750458\n",
      "Estimated loss diff :7.523542879107932e-05\n",
      "[18/50]\n",
      "LBFGS training took [23] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01708949]\n",
      "True loss diff      :0.00016381405293941498\n",
      "Estimated loss diff :8.39534506260171e-05\n",
      "[19/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01707427]\n",
      "True loss diff      :0.00014859624207019806\n",
      "Estimated loss diff :8.464570526622778e-05\n",
      "[20/50]\n",
      "LBFGS training took [23] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01707639]\n",
      "True loss diff      :0.00015071779489517212\n",
      "Estimated loss diff :8.891011813319397e-05\n",
      "[21/50]\n",
      "LBFGS training took [23] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01708997]\n",
      "True loss diff      :0.00016429834067821503\n",
      "Estimated loss diff :9.651004321809606e-05\n",
      "[22/50]\n",
      "LBFGS training took [21] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01707718]\n",
      "True loss diff      :0.00015150569379329681\n",
      "Estimated loss diff :9.702814010724378e-05\n",
      "[23/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01718735]\n",
      "True loss diff      :0.0002616792917251587\n",
      "Estimated loss diff :0.0001322792538963622\n",
      "[24/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01717001]\n",
      "True loss diff      :0.00024433620274066925\n",
      "Estimated loss diff :0.00016536895064559018\n",
      "[25/50]\n",
      "LBFGS training took [21] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.0171959]\n",
      "True loss diff      :0.0002702288329601288\n",
      "Estimated loss diff :0.00024263095647667155\n",
      "[26/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.0165051]\n",
      "True loss diff      :-0.000420568510890007\n",
      "Estimated loss diff :-0.00047350401693040426\n",
      "[27/50]\n",
      "LBFGS training took [23] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01668909]\n",
      "True loss diff      :-0.00023658014833927155\n",
      "Estimated loss diff :-0.0002612114902647322\n",
      "[28/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01675697]\n",
      "True loss diff      :-0.00016869790852069855\n",
      "Estimated loss diff :-0.00024087626698671136\n",
      "[29/50]\n",
      "LBFGS training took [23] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01677352]\n",
      "True loss diff      :-0.00015215016901493073\n",
      "Estimated loss diff :-0.00023113536419541828\n",
      "[30/50]\n",
      "LBFGS training took [21] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01673479]\n",
      "True loss diff      :-0.00019088014960289001\n",
      "Estimated loss diff :-0.00021207918298205984\n",
      "[31/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01678534]\n",
      "True loss diff      :-0.00014032982289791107\n",
      "Estimated loss diff :-0.00018415933324105276\n",
      "[32/50]\n",
      "LBFGS training took [23] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01688518]\n",
      "True loss diff      :-4.049576818943024e-05\n",
      "Estimated loss diff :-0.00018299508178532879\n",
      "[33/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01682323]\n",
      "True loss diff      :-0.00010244548320770264\n",
      "Estimated loss diff :-0.00016907738333955629\n",
      "[34/50]\n",
      "LBFGS training took [21] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01681498]\n",
      "True loss diff      :-0.00011068955063819885\n",
      "Estimated loss diff :-0.00016834252593637733\n",
      "[35/50]\n",
      "LBFGS training took [21] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01685566]\n",
      "True loss diff      :-7.001683115959167e-05\n",
      "Estimated loss diff :-0.00014414872933774005\n",
      "[36/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01681432]\n",
      "True loss diff      :-0.00011135637760162354\n",
      "Estimated loss diff :-0.00014114795995762632\n",
      "[37/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01685262]\n",
      "True loss diff      :-7.304735481739044e-05\n",
      "Estimated loss diff :-0.00013337921939187076\n",
      "[38/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01686681]\n",
      "True loss diff      :-5.8863312005996704e-05\n",
      "Estimated loss diff :-0.00013005778126454678\n",
      "[39/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01688124]\n",
      "True loss diff      :-4.443526268005371e-05\n",
      "Estimated loss diff :-0.00012947322702374842\n",
      "[40/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01686166]\n",
      "True loss diff      :-6.401538848876953e-05\n",
      "Estimated loss diff :-0.00012296023070835138\n",
      "[41/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01685287]\n",
      "True loss diff      :-7.280521094799042e-05\n",
      "Estimated loss diff :-0.0001223466652001207\n",
      "[42/50]\n",
      "LBFGS training took [23] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01688403]\n",
      "True loss diff      :-4.164688289165497e-05\n",
      "Estimated loss diff :-0.00012088367736815233\n",
      "[43/50]\n",
      "LBFGS training took [23] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.0168873]\n",
      "True loss diff      :-3.8372352719306946e-05\n",
      "Estimated loss diff :-0.0001173710718749808\n",
      "[44/50]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01684335]\n",
      "True loss diff      :-8.232146501541138e-05\n",
      "Estimated loss diff :-0.00011726672737298907\n",
      "[45/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.0168736]\n",
      "True loss diff      :-5.2073970437049866e-05\n",
      "Estimated loss diff :-0.00011490029893271918\n",
      "[46/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01690045]\n",
      "True loss diff      :-2.5218352675437927e-05\n",
      "Estimated loss diff :-0.00011356703280037001\n",
      "[47/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01687384]\n",
      "True loss diff      :-5.182996392250061e-05\n",
      "Estimated loss diff :-0.0001097887285019934\n",
      "[48/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01688675]\n",
      "True loss diff      :-3.8918107748031616e-05\n",
      "Estimated loss diff :-0.00010084981624183954\n",
      "[49/50]\n",
      "LBFGS training took [21] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01692973]\n",
      "True loss diff      :4.062429070472717e-06\n",
      "Estimated loss diff :-9.818728665220588e-05\n",
      "[50/50]\n",
      "LBFGS training took [22] iter.\n",
      "Original loss       :[0.01692567]\n",
      "Retrain loss        :[0.01690009]\n",
      "True loss diff      :-2.5581568479537964e-05\n",
      "Estimated loss diff :-9.680113067719153e-05\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_NUM = 50 \n",
    "\n",
    "# get high and low loss diff indice\n",
    "sorted_indice = np.argsort(loss_diff_approx)\n",
    "sample_indice = np.concatenate([sorted_indice[-int(SAMPLE_NUM/2):], sorted_indice[:int(SAMPLE_NUM/2)]])\n",
    "\n",
    "\n",
    "# calculate true loss diff\n",
    "loss_diff_true = np.zeros(SAMPLE_NUM)\n",
    "for i, index in zip(range(SAMPLE_NUM), sample_indice):\n",
    "    print('[{}/{}]'.format(i+1, SAMPLE_NUM))\n",
    "\n",
    "    # get minus one dataset\n",
    "    x_train_minus_one = np.delete(x_train, index, axis=0)\n",
    "    y_train_minus_one = np.delete(y_train, index, axis=0)\n",
    "\n",
    "    # retrain\n",
    "    C = 1.0 / ((train_sample_num - 1) * WEIGHT_DECAY)\n",
    "    sklearn_model_minus_one = linear_model.LogisticRegression(C=C, fit_intercept=False, tol=1e-8, solver='lbfgs')\n",
    "    sklearn_model_minus_one.fit(x_train_minus_one, y_train_minus_one.ravel())\n",
    "    print('LBFGS training took {} iter.'.format(sklearn_model_minus_one.n_iter_))\n",
    "\n",
    "    # Reference model (deep learning)\n",
    "    w_ref = sklearn_model_minus_one.coef_.T.ravel()\n",
    "    b_ref = sklearn_model_minus_one.intercept_.ravel()\n",
    "    model.set_weights([w_ref.reshape(784, 1), b_ref])\n",
    "    \n",
    "\n",
    "    # get retrain loss\n",
    "    x_test_tf = tf.convert_to_tensor(x_test[TEST_INDEX: TEST_INDEX+1])\n",
    "    y_test_tf = tf.convert_to_tensor(y_test[TEST_INDEX: TEST_INDEX+1])\n",
    "    y_hat = model(x_test_tf)\n",
    "    test_loss_retrain = tf.keras.losses.binary_crossentropy(y_test_tf, y_hat)\n",
    "\n",
    "    # get true loss diff\n",
    "    loss_diff_true[i] = test_loss_retrain.numpy() - test_loss_ori.numpy()\n",
    "\n",
    "    print('Original loss       :{}'.format(test_loss_ori))\n",
    "    print('Retrain loss        :{}'.format(test_loss_retrain))\n",
    "    print('True loss diff      :{}'.format(loss_diff_true[i]))\n",
    "    print('Estimated loss diff :{}'.format(loss_diff_approx[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_result(actual_loss_diff, estimated_loss_diff):\n",
    "    max_abs = np.max([np.abs(actual_loss_diff), np.abs(estimated_loss_diff)])\n",
    "    min_, max_ = -max_abs * 1.15, max_abs * 1.15\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = 6, 5\n",
    "    plt.scatter(actual_loss_diff, estimated_loss_diff, zorder=2, s=10)\n",
    "    plt.title('Loss diff')\n",
    "    plt.xlabel('Actual loss diff')\n",
    "    plt.ylabel('Estimated loss diff')\n",
    "    \n",
    "    range_ = [min_, max_]\n",
    "    plt.plot(range_, range_, 'k-', alpha=0.2, zorder=1)\n",
    "    text = 'MAE = {:.03}\\nR2 score = {:.03}'.format(mean_absolute_error(actual_loss_diff, estimated_loss_diff),\n",
    "                                                    r2_score(actual_loss_diff, estimated_loss_diff))\n",
    "    plt.text(max_abs, -max_abs, text, verticalalignment='bottom', horizontalalignment='right')\n",
    "    plt.xlim(min_, max_)\n",
    "    plt.ylim(min_, max_)\n",
    "    plt.show()\n",
    "    \n",
    "visualize_result(loss_diff_true, loss_diff_approx[sample_indice])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
